1. Inside extract_landmarks.py, change number_of_classes (line 10) depending no the amount of hand gestures you want to make
2. Run extract_landmarks.py and start collecting images using webcam. Press q right after recording a hand gesture to record the next one.
3. Run create_dataset after collecting images for the dataset.
4. Run train_model.py to start training
5. Inside the real_time_prediction.py, at line 33 labels dict, define hand gestures based on their folder name in the "data" folder.
6. Run real_time_prediction.py to start predicting asl.

------------------------NOT FINAL README------------------------------
